{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:29:31.379449Z",
     "start_time": "2024-12-19T04:29:29.777283Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fc5bc112d2190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08860633-cb69-46ea-964a-7bbac0b7913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f8e347-eb48-4f65-8451-96edb6ce03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b448017-31fa-4dc2-9ae0-461ccfc5a52b",
   "metadata": {},
   "source": [
    "Модифицируем функцию чтения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da7d1fb-bd17-4e4e-982f-d6e99c6fe050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s, rus = False):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"([\\s+])\", r\" \", s)\n",
    "    if rus:\n",
    "        s = re.sub(r\"[^а-яА-ЯёЁ.!?]+\", r\" \", s)\n",
    "    else:\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    if lang2 is not None:\n",
    "        lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "        pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    else:\n",
    "        lines = open('data/%s.txt' % (lang1), encoding='utf-8').read().strip().split('\\n')\n",
    "        lines = [[s for i, s in enumerate(l.split('\\t')) if i in [0,1] ] for l in lines]\n",
    "        pairs = [[ normalizeString(l[0]),normalizeString(l[1], rus=True) ] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeab8b06-f6b0-4be7-a4c0-ef622bc0288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68867f38-8c76-4000-b2b8-4e59b632c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2 =None, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf8db3b-a71d-4787-8f30-056710c718a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28719 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "None 10174\n",
      "rus 4303\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('rus', None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ac3369-140b-45b8-b8fa-4361c600ae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['она улыбнулась в ответ на его нежныи взгляд .',\n",
       "  'she smiled in response to his affectionate glance .'],\n",
       " ['она проводит каждое воскресенье со своеи бабушкои .',\n",
       "  'she spends time with her grandmother every sunday .'],\n",
       " ['каждую субботу после обеда она играет в теннис .',\n",
       "  'she spends every saturday afternoon playing tennis .'],\n",
       " ['после аварии она перестала бывать на людях .',\n",
       "  'she stopped appearing in public after her accident .'],\n",
       " ['они ведут переговоры чтобы приити к приемлемому компромиссу .',\n",
       "  'they are negotiating to reach a satisfactory compromise .']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c324c-0520-46ef-b40d-553a3a0f336c",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867687d4-9f08-4442-b53b-e5458256c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672e7015-ebef-44a9-8c38-f7fbbdcbc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder( decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca85d649-9582-42b0-bccd-11294e11f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9f8f06-d39b-42d5-9391-e71a6b114247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef46d07c-8026-4489-83cf-5d7ebabe8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9faed0de-2ae0-4548-b517-4c6d65608475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77a76194-4b14-4f01-bb27-bad7d64c0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 41s (- 9m 45s) (5000 6%) 3.1193\n",
      "1m 19s (- 8m 36s) (10000 13%) 2.6248\n",
      "1m 57s (- 7m 48s) (15000 20%) 2.3431\n",
      "2m 34s (- 7m 5s) (20000 26%) 2.1771\n",
      "3m 12s (- 6m 25s) (25000 33%) 1.9861\n",
      "3m 50s (- 5m 46s) (30000 40%) 1.8850\n",
      "4m 28s (- 5m 7s) (35000 46%) 1.7698\n",
      "5m 6s (- 4m 28s) (40000 53%) 1.6245\n",
      "5m 44s (- 3m 49s) (45000 60%) 1.5321\n",
      "6m 22s (- 3m 11s) (50000 66%) 1.4711\n",
      "7m 0s (- 2m 33s) (55000 73%) 1.4310\n",
      "7m 38s (- 1m 54s) (60000 80%) 1.3418\n",
      "8m 16s (- 1m 16s) (65000 86%) 1.2850\n",
      "8m 54s (- 0m 38s) (70000 93%) 1.2439\n",
      "9m 32s (- 0m 0s) (75000 100%) 1.2127\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c6d09c1-7dfb-413e-9f3e-cb1618464f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> вы станете знаменитым .\n",
      "= you re going to be famous .\n",
      "< you re going to be famous . <EOS>\n",
      "\n",
      "> мы помолвлены .\n",
      "= we re engaged .\n",
      "< we re going . <EOS>\n",
      "\n",
      "> ты ослеплен любовью .\n",
      "= you are blinded by love .\n",
      "< you re my a . <EOS>\n",
      "\n",
      "> я всегда озадачен .\n",
      "= i m always confused .\n",
      "< i m always tired . <EOS>\n",
      "\n",
      "> я очень больнои человек .\n",
      "= i m a very sick person .\n",
      "< i m a very busy person . <EOS>\n",
      "\n",
      "> я не такая высокая как ты .\n",
      "= i m not as tall as you .\n",
      "< i m not as tall as you . <EOS>\n",
      "\n",
      "> они очень важны .\n",
      "= they are very important .\n",
      "< they are very important . <EOS>\n",
      "\n",
      "> я занята так что не могу поити .\n",
      "= i m busy so i can t go .\n",
      "< i m busy so i can t go . <EOS>\n",
      "\n",
      "> я собираюсь в бостон этои осенью .\n",
      "= i m going to boston this fall .\n",
      "< i m going to go this this . <EOS>\n",
      "\n",
      "> я рад что мы можем помочь .\n",
      "= i m glad we can help .\n",
      "< i m glad we can help . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fd931-6a86-4e20-8967-93994c659d4f",
   "metadata": {},
   "source": [
    "## Попробуем добавить +1 рекуррентный слой в encoder и decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b70a3ca-0356-4a03-b6aa-c8ba207ee6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(2, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size , num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(2, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3224b88-0bef-42f2-b95d-daf153044127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (- 12m 7s) (5000 6%) 3.1276\n",
      "1m 40s (- 10m 53s) (10000 13%) 2.7179\n",
      "2m 28s (- 9m 53s) (15000 20%) 2.4281\n",
      "3m 16s (- 8m 59s) (20000 26%) 2.2424\n",
      "4m 4s (- 8m 8s) (25000 33%) 2.0526\n",
      "4m 51s (- 7m 17s) (30000 40%) 1.9292\n",
      "5m 40s (- 6m 29s) (35000 46%) 1.8049\n",
      "6m 28s (- 5m 39s) (40000 53%) 1.7041\n",
      "7m 18s (- 4m 52s) (45000 60%) 1.6100\n",
      "8m 6s (- 4m 3s) (50000 66%) 1.5015\n",
      "8m 55s (- 3m 14s) (55000 73%) 1.4615\n",
      "9m 43s (- 2m 25s) (60000 80%) 1.3626\n",
      "10m 32s (- 1m 37s) (65000 86%) 1.3109\n",
      "11m 21s (- 0m 48s) (70000 93%) 1.2581\n",
      "12m 9s (- 0m 0s) (75000 100%) 1.1912\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33beed2f-0105-4073-bef9-67c5549cd42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> сожалею о прошлои ночи .\n",
      "= i m sorry about last night .\n",
      "< i m sorry about about this . . <EOS>\n",
      "\n",
      "> я не ревнивыи человек .\n",
      "= i m not a jealous person .\n",
      "< i m not a person . <EOS>\n",
      "\n",
      "> ты у меня в руках .\n",
      "= you re in my hands .\n",
      "< you re in my room . <EOS>\n",
      "\n",
      "> он здесь чтобы следить за нами .\n",
      "= he s here to spy on us .\n",
      "< he is here to to our job . <EOS>\n",
      "\n",
      "> они холодные .\n",
      "= they re cold .\n",
      "< they re getting . <EOS>\n",
      "\n",
      "> мы самостоятельная нация .\n",
      "= we are an independent nation .\n",
      "< we re in a a . . <EOS>\n",
      "\n",
      "> я кое кого жду .\n",
      "= i m expecting someone .\n",
      "< i m expecting for . . <EOS>\n",
      "\n",
      "> они мне не враги .\n",
      "= they re not my enemies .\n",
      "< they re not my . . <EOS>\n",
      "\n",
      "> я ничего не выбрасываю .\n",
      "= i m not throwing anything away .\n",
      "< i m not doing anything . <EOS>\n",
      "\n",
      "> это все я сделал .\n",
      "= i m the one who did all this .\n",
      "< i m the one who did that . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1bd18-53c9-4599-9600-8c3b69aa489e",
   "metadata": {},
   "source": [
    "### Добавим вместо слоя GRU слой LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "622ca5ca-2e2c-41cc-b566-a3657e591d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, -1)\n",
    "        output = embedded\n",
    "\n",
    "        output, (hn, cn) = self.lstm(output, (hidden[0], hidden[1]))\n",
    "        return output, (hn, cn)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (\n",
    "            torch.zeros( 1, self.hidden_size, device=device),\n",
    "            torch.zeros( 1, self.hidden_size, device=device),\n",
    "        )\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size )\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, (hidden_, c_n)  = self.gru(output, (hidden[0], hidden[1]))\n",
    "        output = self.softmax(self.out(output))\n",
    "        return output, (hidden_, c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a757c0-d5e6-49e4-99f4-32600b9b127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 44s (- 10m 22s) (5000 6%) 3.2158\n",
      "1m 25s (- 9m 14s) (10000 13%) 2.7478\n",
      "2m 6s (- 8m 27s) (15000 20%) 2.5676\n",
      "2m 47s (- 7m 39s) (20000 26%) 2.3289\n",
      "3m 28s (- 6m 57s) (25000 33%) 2.2117\n",
      "4m 10s (- 6m 15s) (30000 40%) 2.0843\n",
      "4m 51s (- 5m 33s) (35000 46%) 1.9667\n",
      "5m 32s (- 4m 51s) (40000 53%) 1.9064\n",
      "6m 13s (- 4m 9s) (45000 60%) 1.8037\n",
      "6m 55s (- 3m 27s) (50000 66%) 1.7326\n",
      "7m 37s (- 2m 46s) (55000 73%) 1.6606\n",
      "8m 18s (- 2m 4s) (60000 80%) 1.6214\n",
      "8m 59s (- 1m 22s) (65000 86%) 1.5491\n",
      "9m 40s (- 0m 41s) (70000 93%) 1.4801\n",
      "10m 22s (- 0m 0s) (75000 100%) 1.4216\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77bfe269-b126-4983-86f6-a73f6a1e4eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> я не большои любитель баскетбола .\n",
      "= i m not a big fan of basketball .\n",
      "< i m not a big of of . . <EOS>\n",
      "\n",
      "> они удивительно хороши .\n",
      "= they re surprisingly good .\n",
      "< they re waiting they . <EOS>\n",
      "\n",
      "> ты не такои маленькии как я .\n",
      "= you aren t as short as i am .\n",
      "< you aren t like me as i am . <EOS>\n",
      "\n",
      "> я такое трепло .\n",
      "= i m such a blabbermouth .\n",
      "< i m the the one who understands . <EOS>\n",
      "\n",
      "> она член этои организации .\n",
      "= she is a member of this organization .\n",
      "< she is a member of this . . <EOS>\n",
      "\n",
      "> ты снова врешь мне .\n",
      "= you re lying to me again .\n",
      "< you re lying to me again again . <EOS>\n",
      "\n",
      "> я вряд ли выиграю .\n",
      "= i m not likely to win .\n",
      "< i m not likely to be . <EOS>\n",
      "\n",
      "> он носитель англииского языка .\n",
      "= he is a native english speaker .\n",
      "< he is a new and . . <EOS>\n",
      "\n",
      "> вы дебилы .\n",
      "= you re morons .\n",
      "< you re shy . <EOS>\n",
      "\n",
      "> им всегда не хватает денег .\n",
      "= they are always short of money .\n",
      "< they re always trying money . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3f0a8-89c3-4e3d-8389-a1e9ee4cf3bf",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "- обучили модель перевода с руского на английский\n",
    "- модель на основе одного слоя GRU , двух слоев GRU, одного слоя LSTM\n",
    "Качество не очень хорошее (по смыслу предложения близки у всех, но минимальная ошибка у модели с двумя GRU слоями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dc7f39-e4d0-4b62-9c1a-21e8e0e07dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
