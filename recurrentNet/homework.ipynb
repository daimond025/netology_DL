{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import time \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ab8c2c-e7d4-435f-936b-59b85f493d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daimond025\\AppData\\Local\\Temp\\ipykernel_281880\\3071692218.py:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/simpsons_script_lines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a92af1-b78a-43d6-bba9-a307ba6c67d0",
   "metadata": {},
   "source": [
    "### Повторим действия преобразования текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8743e77-7272-4115-9400-eaabbd04c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daimond025\\AppData\\Local\\Temp\\ipykernel_281880\\3071692218.py:1: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/simpsons_script_lines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d1d502-c734-425e-9401-aebf11952eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = df['normalized_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72541c86-5518-4b6f-8427-d4dd4927b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[c for c in ph] for ph in phrases if type(ph) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882841c4-d07f-4e32-9476-742a7ffe3709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 't',\n",
       " 'i',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'e',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'g',\n",
       " 'a',\n",
       " 'z',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'w',\n",
       " 's',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 'n',\n",
       " 'k',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 't']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adaeb33b-8093-4fe9-89b3-213660f06fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = set('abcdefghijklmnopqrstuvwxyz ') \n",
    "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd3da94-4fe2-469c-a633-1502e8a3b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50 \n",
    "X = torch.zeros((len(text), MAX_LEN), dtype=int)  \n",
    "for i in range(len(text)):  \n",
    "    for j, w in enumerate(text[i]):  \n",
    "        if j >= MAX_LEN:\n",
    "            break\n",
    "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcfb2edc-5a55-41c5-baa1-2139f83aaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  7, 10, 25,  8,  3, 16, 25, 14, 14, 19, 10, 26,  3, 10,  5, 25,  6,\n",
       "        10, 25, 10, 14, 26,  3,  3, 14, 17, 10,  7,  1, 10, 18,  7,  3, 21, 10,\n",
       "         6,  7,  4, 17,  3, 26,  4, 17,  6, 10,  5, 21, 17, 12])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc21d5af-fea9-4c59-867a-a8e409fadf87",
   "metadata": {},
   "source": [
    "Базовая модель  c применением слоя RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56df2839-5f65-4490-93cb-1a7d531bb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network_base, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(28, 30)\n",
    "        self.rnn = torch.nn.RNN(30, 128)\n",
    "        self.out = torch.nn.Linear(128, 28)\n",
    "\n",
    "    def forward(self, sentences, state=None):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x) \n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94469dc8-5952-4c9e-8962-05cf2a8443eb",
   "metadata": {},
   "source": [
    "Построим RNN-ячейку на основе полносвязных слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "146084b9-8010-42f7-9d4e-023572c19d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        x = self.i2h(input)\n",
    "\n",
    "        hidden_state = self.h2h(hidden)\n",
    "        hidden_out = hidden_state.unsqueeze(0)\n",
    "\n",
    "        hidden_state = torch.tanh(x + hidden_out)\n",
    "        output = self.h2o(hidden_state)\n",
    "        return output, hidden_state\n",
    "        \n",
    "    @staticmethod\n",
    "    def initHidden(hidden_size):\n",
    "        return torch.zeros(1, hidden_size)\n",
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(28, 30)\n",
    "        self.rnn = RNN(30,  128,  128 )\n",
    "        self.out = torch.nn.Linear(128, 28)\n",
    "\n",
    "    def forward(self, sentences, hidden=torch.Tensor):\n",
    "        x = self.embedding(sentences)\n",
    "        x, s = self.rnn(x, hidden= hidden)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd36e9-a425-495b-9fad-b7f9f3c047d1",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf3e9cd5-55b5-47b4-8a02-4eac5b2076b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32fd5f4-ae2e-41a4-a3d4-fd26147682c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 4.497, Train loss: 1.686\n",
      "Epoch 1. Time: 4.457, Train loss: 1.686\n",
      "Epoch 2. Time: 4.422, Train loss: 1.686\n",
      "Epoch 3. Time: 4.436, Train loss: 1.686\n",
      "Epoch 4. Time: 4.188, Train loss: 1.686\n",
      "Epoch 5. Time: 4.128, Train loss: 1.686\n",
      "Epoch 6. Time: 4.063, Train loss: 1.685\n",
      "Epoch 7. Time: 4.047, Train loss: 1.685\n",
      "Epoch 8. Time: 4.105, Train loss: 1.685\n",
      "Epoch 9. Time: 4.085, Train loss: 1.685\n"
     ]
    }
   ],
   "source": [
    "step_count = 100\n",
    "for ep in range(10):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / step_count)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # для каждого батча сформируем скрытй слов слой \n",
    "        hidden = RNN.initHidden(hidden_size=128)\n",
    "\n",
    "        batch = X[i * step_count: (i + 1) * step_count]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        answers = model.forward(X_batch, hidden=hidden)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c10f3734-2268-425b-84cb-2f3a21988487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(word):\n",
    "    sentence = list(word)\n",
    "    sentence = [CHAR_TO_INDEX.get(s, 0) for s in sentence]\n",
    "    hidden = RNN.initHidden(hidden_size=128)\n",
    "    \n",
    "    answers = model.forward(torch.tensor(sentence), hidden=hidden)\n",
    "    probas, indices = answers.topk(1)\n",
    "    return ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0f663ac-ad08-4c09-a706-5310d80ebf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' u '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03746138-d444-4fe0-a039-602d1510719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' nee u  '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence('simpsons')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416a24e-04d7-4539-9edc-9e09e6d209cc",
   "metadata": {},
   "source": [
    "### Обучим стандратную ячейку с rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5791b03-7761-4c75-8423-8b8827ee404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network_base()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab371b20-38c6-43ce-a57b-a7745a09131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Time: 14.067, Train loss: 1.828\n",
      "Epoch 1. Time: 13.458, Train loss: 1.724\n",
      "Epoch 2. Time: 12.773, Train loss: 1.707\n",
      "Epoch 3. Time: 12.671, Train loss: 1.698\n",
      "Epoch 4. Time: 12.729, Train loss: 1.691\n",
      "Epoch 5. Time: 12.736, Train loss: 1.685\n",
      "Epoch 6. Time: 12.624, Train loss: 1.681\n",
      "Epoch 7. Time: 12.684, Train loss: 1.678\n",
      "Epoch 8. Time: 12.680, Train loss: 1.675\n",
      "Epoch 9. Time: 12.624, Train loss: 1.672\n"
     ]
    }
   ],
   "source": [
    "for ep in range(10):\n",
    "    start = time.time()\n",
    "    train_loss = 0.\n",
    "    train_passed = 0\n",
    "\n",
    "    for i in range(int(len(X) / 100)):\n",
    "        # берём батч в 100 элементов\n",
    "        batch = X[i * 100:(i + 1) * 100]\n",
    "        X_batch = batch[:, :-1]\n",
    "        Y_batch = batch[:, 1:].flatten()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        answers = model.forward(X_batch)\n",
    "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
    "        loss = criterion(answers, Y_batch)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_passed += 1\n",
    "\n",
    "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5205d34f-5702-4069-9157-7dc2a43af821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_base(word):\n",
    "    sentence = list(word)\n",
    "    sentence = [CHAR_TO_INDEX.get(s, 0) for s in sentence]\n",
    "    answers = model.forward(torch.tensor(sentence))\n",
    "    probas, indices = answers.topk(1)\n",
    "    return ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fbed7f0-e35f-4754-a36b-2709068d676f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' uo'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence_base('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbdee857-f163-47ad-98a2-673d05adb418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'none tn '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence_base('It is')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f80656-a34b-45fc-8591-544124d7f519",
   "metadata": {},
   "source": [
    "#### Вывод \n",
    "Построили две моделт с rnn ячейкой и  RNN ячейкой на основе полносвязных слоев\n",
    "Вывод обеих моделей примерно равны \n",
    "\n",
    "\n",
    "## Обучим нейронную сеть решать шифр Цезар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5226ab2-5429-4baa-b40e-c0e926a1dcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daimond025\\AppData\\Local\\Temp\\ipykernel_281880\\2458915655.py:36: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from random import shuffle\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "STRING_SIZE = 50\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.05\n",
    "CAESAR_OFFSET = 2\n",
    "\n",
    "class Alphabet():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.letters = \"\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.letters)\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self.letters\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if isinstance(item, int):\n",
    "            return self.letters[item % len(self.letters)]\n",
    "        elif isinstance(item, str):\n",
    "            return self.letters.find(item)\n",
    "\n",
    "    def __str__(self):\n",
    "        letters = \" \".join(self.letters)\n",
    "        return f\"Alphabet is:\\n {letters}\\n {len(self)} chars\"\n",
    "\n",
    "\n",
    "    def load_from_df(self,):\n",
    "        df = pd.read_csv('data/simpsons_script_lines.csv')\n",
    "        df.dropna(subset=['normalized_text'], inplace=True)\n",
    "        phrases = df['normalized_text'].tolist()\n",
    "        for text in phrases:\n",
    "            for ch in text:\n",
    "                if type(ch) is str and ch not in self.letters:\n",
    "                    self.letters += ch\n",
    "        return self\n",
    "ALPHABET = Alphabet().load_from_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bfb61fa-5a81-4873-b91a-1daeec1ea922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet is:\n",
      " n o   a c t u l y i w s e f b h m d g z r k v p j - x 5 q 1 0 9 7 3 ñ 6 8 2 4 _ Ñ é ä ï á à ü è ì ö â D . H \" ë ó ! í ç É ' B T õ M ô å ê ú È ? Ù û ł ż ń Ä ǒ ǐ ǎ ē ā ě ī ò E N : ) U ù Ĭ Ö æ ø Ĉ ŭ Ĝ ã W I A R C S F P L\n",
      " 109 chars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ALPHABET)\n",
    "len(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad0810a2-2719-47c3-8ef2-9a09a74d5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, raw_data, alphabet):\n",
    "        super().__init__()\n",
    "        self._len = len(raw_data)\n",
    "\n",
    "\n",
    "        self.y = torch.zeros((len(raw_data), STRING_SIZE), dtype=int)\n",
    "        for i in range(len(raw_data)):\n",
    "            for j, ch in enumerate(raw_data[i]):\n",
    "                if j >= STRING_SIZE:\n",
    "                    break\n",
    "                self.y[i, j] = alphabet[ch]\n",
    "\n",
    "        self.x = torch.tensor([ [i + CAESAR_OFFSET for i in line ] for line in self.y] )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c005d6e-3953-4ed5-8ced-68311e5efa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_array():\n",
    "    text_array = []\n",
    "    df = pd.read_csv('data/simpsons_script_lines.csv')\n",
    "    df.dropna(subset=['normalized_text'], inplace=True)\n",
    "    phrases = df['normalized_text'].tolist()\n",
    "    for text in phrases:\n",
    "        text_array.append(text)\n",
    "    del text_array[-1]\n",
    "\n",
    "    return text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bacb882-0cae-494f-9523-a1d8a7e45306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daimond025\\AppData\\Local\\Temp\\ipykernel_281880\\1714548643.py:3: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/simpsons_script_lines.csv')\n"
     ]
    }
   ],
   "source": [
    "raw_data = get_text_array()\n",
    "shuffle(raw_data)\n",
    "_10_percent = math.ceil(len(raw_data) * 0.1)\n",
    "\n",
    "val_data = raw_data[:_10_percent]\n",
    "raw_data = raw_data[_10_percent:]\n",
    "\n",
    "_20_percent = math.ceil(len(raw_data) * 0.2)\n",
    "test_data = raw_data[:_20_percent]\n",
    "train_data = raw_data[_20_percent:]\n",
    "\n",
    "Y_val = torch.zeros((len(val_data), STRING_SIZE), dtype=int)\n",
    "for i in range(len(val_data)):\n",
    "    for j, ch in enumerate(val_data[i]):\n",
    "        if j >= STRING_SIZE:\n",
    "            break\n",
    "        Y_val[i, j] = ALPHABET[ch]\n",
    "\n",
    "X_val = torch.tensor([[i + CAESAR_OFFSET for i in line] for line in Y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7feb47b3-7f57-49aa-be89-e71481056e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(len(ALPHABET) + CAESAR_OFFSET, 32)\n",
    "        self.rnn = torch.nn.RNN(32, 128, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(128, len(ALPHABET) + CAESAR_OFFSET)\n",
    "\n",
    "    def forward(self, sentence, state=None):\n",
    "        embed = self.embed(sentence)\n",
    "        o, h = self.rnn(embed)\n",
    "        return self.linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17b0ef1c-3637-42f0-8985-9beac77f76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    SentenceDataset(\n",
    "        train_data, ALPHABET\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    SentenceDataset(\n",
    "        test_data, ALPHABET\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "118ecfb8-2174-48fc-b639-5b54d108ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 413.4166, acc: 0.9937 | test loss: 9.0692, test acc: 0.9996 | 42.08 sec.\n",
      "Epoch: 1, loss: 28.9587, acc: 0.9996 | test loss: 5.8772, test acc: 0.9996 | 42.21 sec.\n",
      "Epoch: 2, loss: 21.1537, acc: 0.9997 | test loss: 4.5531, test acc: 0.9997 | 41.86 sec.\n",
      "Epoch: 3, loss: 16.9223, acc: 0.9997 | test loss: 3.6964, test acc: 0.9997 | 39.97 sec.\n",
      "Epoch: 4, loss: 13.9449, acc: 0.9998 | test loss: 3.0580, test acc: 0.9998 | 40.93 sec.\n",
      "Epoch: 5, loss: 11.7539, acc: 0.9998 | test loss: 2.5800, test acc: 0.9998 | 38.96 sec.\n",
      "Epoch: 6, loss: 10.1039, acc: 0.9998 | test loss: 2.2140, test acc: 0.9999 | 38.63 sec.\n",
      "Epoch: 7, loss: 8.8224, acc: 0.9999 | test loss: 1.9263, test acc: 0.9999 | 38.64 sec.\n",
      "Epoch: 8, loss: 7.8006, acc: 0.9999 | test loss: 1.6952, test acc: 0.9999 | 38.54 sec.\n",
      "Epoch: 9, loss: 6.9724, acc: 0.9999 | test loss: 1.5082, test acc: 0.9999 | 38.60 sec.\n",
      "Epoch: 10, loss: 6.2939, acc: 0.9999 | test loss: 1.3552, test acc: 0.9999 | 38.58 sec.\n",
      "Epoch: 11, loss: 5.7351, acc: 0.9999 | test loss: 1.2298, test acc: 1.0000 | 38.54 sec.\n",
      "Epoch: 12, loss: 5.2739, acc: 1.0000 | test loss: 1.1268, test acc: 1.0000 | 39.11 sec.\n",
      "Epoch: 13, loss: 4.8930, acc: 1.0000 | test loss: 1.0419, test acc: 1.0000 | 39.03 sec.\n",
      "Epoch: 14, loss: 4.5771, acc: 1.0000 | test loss: 0.9719, test acc: 1.0000 | 38.92 sec.\n",
      "Epoch: 15, loss: 4.3159, acc: 1.0000 | test loss: 0.9139, test acc: 1.0000 | 38.85 sec.\n",
      "Epoch: 16, loss: 4.0977, acc: 1.0000 | test loss: 0.8652, test acc: 1.0000 | 38.80 sec.\n",
      "Epoch: 17, loss: 3.9138, acc: 1.0000 | test loss: 0.8241, test acc: 1.0000 | 39.17 sec.\n",
      "Epoch: 18, loss: 3.7577, acc: 1.0000 | test loss: 0.7890, test acc: 1.0000 | 38.73 sec.\n",
      "Epoch: 19, loss: 3.6238, acc: 1.0000 | test loss: 0.7588, test acc: 1.0000 | 38.65 sec.\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc, iter_num = .0, .0, .0\n",
    "    start_epoch_time = time.time()\n",
    "    model.train()\n",
    "    for x_in, y_in in train_dl:\n",
    "        x_in = x_in\n",
    "        y_in = y_in.view(1, -1).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(x_in).view(-1, len(ALPHABET) + CAESAR_OFFSET)\n",
    "        l = loss(out, y_in)\n",
    "        train_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y_in)\n",
    "        train_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        iter_num += 1\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, loss: {train_loss:.4f}, acc: \"\n",
    "        f\"{train_acc / iter_num:.4f}\",\n",
    "        end=\" | \"\n",
    "    )\n",
    "    test_loss, test_acc, iter_num = .0, .0, .0\n",
    "    model.eval()\n",
    "    for x_in, y_in in test_dl:\n",
    "        x_in = x_in\n",
    "        y_in = y_in.view(1, -1).squeeze()\n",
    "        out = model.forward(x_in).view(-1, len(ALPHABET) + CAESAR_OFFSET)\n",
    "        l = loss(out, y_in)\n",
    "        test_loss += l.item()\n",
    "        batch_acc = (out.argmax(dim=1) == y_in)\n",
    "        test_acc += batch_acc.sum().item() / batch_acc.shape[0]\n",
    "        iter_num += 1\n",
    "    print(\n",
    "        f\"test loss: {test_loss:.4f}, test acc: {test_acc / iter_num:.4f} | \"\n",
    "        f\"{time.time() - start_epoch_time:.2f} sec.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "989a46a2-5743-45fe-b419-49c9e93caa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is : 1.0000\n",
      "--------------------\n",
      "Validation sentence is: \"i wanna play dodge-rocknnnnnnnnnnnnnnnnnnnnnnnnnnn\"\n",
      "--------------------\n",
      "True sentence is:       \"i wanna play dodge-rocknnnnnnnnnnnnnnnnnnnnnnnnnnn\"\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "val_results = model(X_val).argmax(dim=2)\n",
    "val_acc = (val_results == Y_val).flatten()\n",
    "val_acc = (val_acc.sum() / val_acc.shape[0]).item()\n",
    "out_sentence = \"\".join([ALPHABET[i.item()]  for i in val_results[idx]])\n",
    "true_sentence = \"\".join([ALPHABET[i.item()] for i in Y_val[idx]])\n",
    "print(f\"Validation accuracy is : {val_acc:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Validation sentence is: \\\"{out_sentence}\\\"\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"True sentence is:       \\\"{true_sentence}\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97341e18-88c7-4a0d-be87-8415dfe8566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted sentence is : fsg-fa fcfsg-fa fcfsg-fa fcfsg-fa fcfsg-fa fc\n",
      "--------------------\n",
      "simpsons simpsons simpsons simpsons simpsons \n"
     ]
    }
   ],
   "source": [
    "sentence = \"simpsons simpsons simpsons simpsons simpsons \"\n",
    "sentence_idx = [ALPHABET[i] for i in sentence]\n",
    "encrypted_sentence_idx = [i + CAESAR_OFFSET for i in sentence_idx]\n",
    "encrypted_sentence = \"\".join([ALPHABET[i] for i in encrypted_sentence_idx])\n",
    "result = model(torch.tensor([encrypted_sentence_idx])).argmax(dim=2)\n",
    "deencrypted_sentence = \"\".join([ALPHABET[i.item()] for i in result.flatten()])\n",
    "print(f\"Encrypted sentence is : {encrypted_sentence}\")\n",
    "print(\"-\" * 20)\n",
    "print(deencrypted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad800b93-e89a-4447-872b-ca625a5b2697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
